# MNIST Digit Generation Using Generative Adversarial Networks (GANs)

This repository contains a PyTorch implementation of a Generative Adversarial Network (GAN) for generating synthetic images of handwritten digits resembling the MNIST dataset. The project focuses on leveraging unsupervised learning techniques to create realistic images through the adversarial training of a generator and discriminator network.

# Project Overview
Generative Adversarial Networks (GANs) are a powerful deep learning approach for generating synthetic data that closely resembles real data distributions. This project aims to train a GAN model to generate images of handwritten digits that are visually indistinguishable from the MNIST dataset.
The GAN architecture consists of two main components:

## Generator: A neural network responsible for generating synthetic images by transforming random noise vectors into images resembling MNIST digits.
## Discriminator: A neural network trained to distinguish between real MNIST images and synthetic images generated by the generator.

During training, the generator and discriminator networks engage in a competitive game, where the generator tries to produce images that can fool the discriminator into classifying them as real, while the discriminator aims to correctly identify real and fake images. This adversarial training process iteratively improves both networks, with the generator learning to produce more realistic images and the discriminator becoming better at distinguishing between real and fake samples.

## Dataset
The project utilizes the renowned MNIST dataset, which consists of 70,000 grayscale images of handwritten digits ranging from 0 to 9. The dataset is split into a training set of 60,000 images and a test set of 10,000 images.
Experiments and Results
The repository includes two main experiments:

- Experiment 1: This experiment sets up a basic GAN architecture with simplistic generator and discriminator models using sequential and linear layers. Activation functions like LeakyReLU, Sigmoid, and Tanh are explored to enhance the models' performance.
- Experiment 2: Building upon the first experiment, this experiment incorporates LeakyReLU activation in both the generator and discriminator architectures and trains the model for a higher number of epochs. The generator and discriminator architectures are expanded, and techniques like dropout are employed to prevent overfitting.

The results of the experiments are visualized, showcasing the generated synthetic images of handwritten digits. The README file provides details on the architecture, hyperparameters, and training process for each experiment.

## Dependencies
The following Python libraries are required to run the code in this repository:

```
PyTorch
NumPy
Matplotlib
```

You can install these dependencies using pip:
```
pip install torch numpy matplotlib
```

## Usage

- Clone the repository to your local machine.
- Navigate to the cloned repository.
- Open the Jupyter Notebook or Python script corresponding to the desired experiment.
- Run the code cells or script to train the GAN model and generate synthetic images.
- Explore the visualizations and generated images to assess the performance of the GAN.

## Contributing
Contributions to this project are welcome. If you find any issues or have suggestions for improvements, please open an issue or submit a pull request.


## Acknowledgments

The MNIST dataset used in this project is a widely known and publicly available dataset.
The project utilizes the PyTorch library for building and training the GAN models.
